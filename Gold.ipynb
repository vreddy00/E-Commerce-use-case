{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "7528edbf-cab1-497d-ad84-27195cc319eb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run ./Silver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1454ca6d-1bb1-4e81-9bcf-3d0900fa4384",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "class WorkFlowRunner:\n",
    "    def __init__(self,name):\n",
    "        self.name=name\n",
    "    def runner(self):\n",
    "        if name==\"TotalRevenueWorkflow\":\n",
    "            firstworkFlow = TotalRevenueWorkflow()\n",
    "            return firstworkFlow.runner()\n",
    "        elif name==\"ProductRevenueWorkflow\":\n",
    "            secondworkFlow = ProductRevenueWorkflow()\n",
    "            return secondworkFlow.runner()\n",
    "        elif name==\"TopSellingWorkflow\":\n",
    "            thirdworkFlow = TopSellingWorkflow()\n",
    "            return thirdworkFlow.runner()\n",
    "        elif name==\"TimelyRevenueWorkflow\":\n",
    "            fourthworkFlow = TimelyRevenueWorkflow()\n",
    "            return fourthworkFlow.runner()\n",
    "        elif name==\"GeoRevenueWorkflow\":\n",
    "            fifthworkFlow = GeoRevenueWorkflow()\n",
    "            return fifthworkFlow.runner()\n",
    "        elif name==\"CustomerValueWorkflow\":\n",
    "            sixthworkFlow = CustomerValueWorkflow()\n",
    "            return sixthworkFlow.runner()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "834a2347-740d-4ae5-9f32-3c4e33eb5597",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "class TotalRevenueWorkflow:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def runner(self):\n",
    "        #step 1 extract required data from different sources\n",
    "        extractor = Order_items()\n",
    "        order_items_Df = extractor.extract()\n",
    "\n",
    "        #step 2 implement the transformation logic\n",
    "        #customers who have bought airpods after buying iphones\n",
    "        preprocessed_order_items_df = get_preprocessed_order_items(order_items_Df)\n",
    "        TotalRevenue = TotalRevenueTransformer()\n",
    "        TotalRevenueTransformerDf = TotalRevenue.transform(preprocessed_order_items_df)\n",
    "        display(TotalRevenueTransformerDf)\n",
    "\n",
    "        TotalRevenueTransformerDf.write.format(\"delta\").mode(\"overwrite\").save(\"abfss://gold@ecommerceproject.dfs.core.windows.net/Result/total_revenue/delta_table\")\n",
    "\n",
    "        spark.sql(\"create table if not exists eco.gold.total_revenue location 'abfss://gold@ecommerceproject.dfs.core.windows.net/Result/total_revenue/delta_table'\")\n",
    "        \n",
    "        gold_df = spark.table(\"eco.gold.total_revenue\")\n",
    "        display(gold_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f7c17b05-0e26-4efb-9b64-e5a47f87c8bb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Databricks visualization. Run in Databricks to view."
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1.subcommand+json": {
       "baseErrorDetails": null,
       "bindings": {},
       "collapsed": false,
       "command": "eco.gold.revenue_trendeco.gold.total_revenueeco.gold.total_revenueeco.gold.total_revenuename = \"TotalRevenueWorkflow\"\n\nworkFlowRunner = WorkFlowRunner(name)\nworkFlowRunner.runner()",
       "commandTitle": "Visualization 1",
       "commandType": "auto",
       "commandVersion": 0,
       "commentThread": [],
       "commentsVisible": false,
       "contentSha256Hex": null,
       "customPlotOptions": {
        "redashChart": [
         {
          "key": "type",
          "value": "COUNTER"
         },
         {
          "key": "options",
          "value": {
           "counterColName": "total_revenue",
           "counterLabel": "total revenue",
           "rowNumber": 1,
           "stringDecChar": ".",
           "stringDecimal": 0,
           "stringThouSep": ",",
           "targetRowNumber": 1,
           "tooltipFormat": "0,0.000"
          }
         }
        ]
       },
       "datasetPreviewNameToCmdIdMap": {},
       "diffDeletes": [],
       "diffInserts": [],
       "displayType": "redashChart",
       "error": null,
       "errorDetails": null,
       "errorSummary": null,
       "errorTraceType": null,
       "finishTime": 0,
       "globalVars": {},
       "guid": "",
       "height": "auto",
       "hideCommandCode": false,
       "hideCommandResult": false,
       "iPythonMetadata": null,
       "inputWidgets": {},
       "isLockedInExamMode": false,
       "latestUser": "a user",
       "latestUserId": null,
       "listResultMetadata": null,
       "metadata": {},
       "nuid": "98e1e345-1982-4c9d-8164-2729e1789497",
       "origId": 0,
       "parentHierarchy": [],
       "pivotAggregation": null,
       "pivotColumns": null,
       "position": 4.375,
       "resultDbfsErrorMessage": null,
       "resultDbfsStatus": "INLINED_IN_TREE",
       "results": null,
       "showCommandTitle": false,
       "startTime": 0,
       "state": "input",
       "streamStates": {},
       "subcommandOptions": {},
       "submitTime": 0,
       "subtype": "tableResultSubCmd.visualization",
       "tableResultIndex": 1,
       "tableResultSettingsMap": {},
       "useConsistentColors": false,
       "version": "CommandV1",
       "width": "auto",
       "workflows": null,
       "xColumns": null,
       "yColumns": null
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "eco.gold.revenue_trendeco.gold.total_revenueeco.gold.total_revenueeco.gold.total_revenuename = \"TotalRevenueWorkflow\"\n",
    "\n",
    "workFlowRunner = WorkFlowRunner(name)\n",
    "workFlowRunner.runner()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b977c98e-eb02-4276-a4f2-f1cd8e978e35",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "class ProductRevenueWorkflow:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def runner(self):\n",
    "        #Extraction\n",
    "        extractor = Order_items()\n",
    "        orderitemDf = extractor.extract()\n",
    "        extractor = Products_Category()\n",
    "        productcatDf = extractor.extract()\n",
    "        extractor = Products()\n",
    "        productDf = extractor.extract()\n",
    "\n",
    "        #Tranformation: Preprocessing\n",
    "        preprocessed_products_df = get_preprocessed_products(productDf)\n",
    "        preprocessed_product_category_df = get_preprocessed_product_category(productcatDf)\n",
    "        preprocessed_order_items_df = get_preprocessed_order_items(orderitemDf)\n",
    "\n",
    "        #Tranformation: Joins\n",
    "        joined_df = productwise_revenue_join(preprocessed_order_items_df,preprocessed_products_df,preprocessed_product_category_df)\n",
    "\n",
    "        #Transformation: Aggregation\n",
    "        revenue_by_product_transformer = RevenueByProductCategoryTransformer()\n",
    "        revenue_result = revenue_by_product_transformer.transform(joined_df)\n",
    "        display(revenue_result)\n",
    "\n",
    "        revenue_result.write.format(\"delta\").mode(\"overwrite\").save(\"abfss://gold@ecommerceproject.dfs.core.windows.net/Result/product_revenue/delta_table\")\n",
    "\n",
    "        spark.sql(\"create table if not exists eco.gold.product_revenue location 'abfss://gold@ecommerceproject.dfs.core.windows.net/Result/product_revenue/delta_table'\")\n",
    "        \n",
    "        gold_df = spark.table(\"eco.gold.product_revenue\")\n",
    "        display(gold_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "549581ce-41c2-496d-bdd4-fe9897224afe",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Databricks visualization. Run in Databricks to view."
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1.subcommand+json": {
       "baseErrorDetails": null,
       "bindings": {},
       "collapsed": false,
       "command": "%python\n__backend_agg_display_orig = display\n__backend_agg_dfs = []\ndef __backend_agg_display_new(df):\n    __backend_agg_df_modules = [\"pandas.core.frame\", \"databricks.koalas.frame\", \"pyspark.sql.dataframe\", \"pyspark.pandas.frame\", \"pyspark.sql.connect.dataframe\"]\n    if (type(df).__module__ in __backend_agg_df_modules and type(df).__name__ == 'DataFrame') or isinstance(df, list):\n        __backend_agg_dfs.append(df)\n\ndisplay = __backend_agg_display_new\n\ndef __backend_agg_user_code_fn():\n    import base64\n    exec(base64.standard_b64decode(\"bmFtZSA9ICJQcm9kdWN0UmV2ZW51ZVdvcmtmbG93IgoKd29ya0Zsb3dSdW5uZXIgPSBXb3JrRmxvd1J1bm5lcihuYW1lKQp3b3JrRmxvd1J1bm5lci5ydW5uZXIoKQ==\").decode())\n\ntry:\n    # run user code\n    __backend_agg_user_code_fn()\n\n    #reset display function\n    display = __backend_agg_display_orig\n\n    if len(__backend_agg_dfs) > 0:\n        # create a temp view\n        if type(__backend_agg_dfs[0]).__module__ == \"databricks.koalas.frame\":\n            # koalas dataframe\n            __backend_agg_dfs[0].to_spark().createOrReplaceTempView(\"DatabricksView7c1ce8f\")\n        elif type(__backend_agg_dfs[0]).__module__ == \"pandas.core.frame\" or isinstance(__backend_agg_dfs[0], list):\n            # pandas dataframe\n            spark.createDataFrame(__backend_agg_dfs[0]).createOrReplaceTempView(\"DatabricksView7c1ce8f\")\n        else:\n            __backend_agg_dfs[0].createOrReplaceTempView(\"DatabricksView7c1ce8f\")\n        #run backend agg\n        display(spark.sql(\"\"\"WITH q AS (select * from DatabricksView7c1ce8f) SELECT `product_category_name_english`,`Category_Revenue` FROM q GROUP BY `Category_Revenue`,`product_category_name_english`\"\"\"))\n    else:\n        displayHTML(\"dataframe no longer exists. If you're using dataframe.display(), use display(dataframe) instead.\")\n\n\nfinally:\n    spark.sql(\"drop view if exists DatabricksView7c1ce8f\")\n    display = __backend_agg_display_orig\n    del __backend_agg_display_new\n    del __backend_agg_display_orig\n    del __backend_agg_dfs\n    del __backend_agg_user_code_fn\n\n",
       "commandTitle": "Visualization 1",
       "commandType": "auto",
       "commandVersion": 0,
       "commentThread": [],
       "commentsVisible": false,
       "contentSha256Hex": null,
       "customPlotOptions": {
        "redashChart": [
         {
          "key": "type",
          "value": "CHART"
         },
         {
          "key": "options",
          "value": {
           "alignYAxesAtZero": true,
           "coefficient": 1,
           "columnConfigurationMap": {
            "series": {
             "column": "Category_Revenue",
             "id": "column_c6cfe46540"
            },
            "x": {
             "column": "product_category_name_english",
             "id": "column_c6cfe46539"
            },
            "y": []
           },
           "dateTimeFormat": "DD/MM/YYYY HH:mm",
           "direction": {
            "type": "counterclockwise"
           },
           "error_y": {
            "type": "data",
            "visible": true
           },
           "globalSeriesType": "column",
           "legend": {
            "traceorder": "normal"
           },
           "missingValuesAsZero": true,
           "numberFormat": "0,0.[00000]",
           "percentFormat": "0[.]00%",
           "series": {
            "error_y": {
             "type": "data",
             "visible": true
            },
            "stacking": null
           },
           "seriesOptions": {},
           "showDataLabels": false,
           "sizemode": "diameter",
           "sortX": true,
           "sortY": true,
           "swappedAxes": false,
           "textFormat": "",
           "useAggregationsUi": true,
           "valuesOptions": {},
           "version": 2,
           "xAxis": {
            "labels": {
             "enabled": true
            },
            "type": "-"
           },
           "yAxis": [
            {
             "type": "-"
            },
            {
             "opposite": true,
             "type": "-"
            }
           ]
          }
         }
        ]
       },
       "datasetPreviewNameToCmdIdMap": {},
       "diffDeletes": [],
       "diffInserts": [],
       "displayType": "redashChart",
       "error": null,
       "errorDetails": null,
       "errorSummary": null,
       "errorTraceType": null,
       "finishTime": 0,
       "globalVars": {},
       "guid": "",
       "height": "auto",
       "hideCommandCode": false,
       "hideCommandResult": false,
       "iPythonMetadata": null,
       "inputWidgets": {},
       "isLockedInExamMode": false,
       "latestUser": "a user",
       "latestUserId": null,
       "listResultMetadata": null,
       "metadata": {},
       "nuid": "f85ad5b2-d6ed-493b-92a9-ebb5fcbdbc33",
       "origId": 0,
       "parentHierarchy": [],
       "pivotAggregation": null,
       "pivotColumns": null,
       "position": 5.5,
       "resultDbfsErrorMessage": null,
       "resultDbfsStatus": "INLINED_IN_TREE",
       "results": null,
       "showCommandTitle": false,
       "startTime": 0,
       "state": "input",
       "streamStates": {},
       "subcommandOptions": {
        "queryPlan": {
         "groups": [
          {
           "column": "product_category_name_english",
           "type": "column"
          },
          {
           "column": "Category_Revenue",
           "type": "column"
          }
         ],
         "selects": [
          {
           "column": "product_category_name_english",
           "type": "column"
          },
          {
           "column": "Category_Revenue",
           "type": "column"
          }
         ]
        }
       },
       "submitTime": 0,
       "subtype": "tableResultSubCmd.visualization",
       "tableResultIndex": 0,
       "tableResultSettingsMap": {},
       "useConsistentColors": false,
       "version": "CommandV1",
       "width": "auto",
       "workflows": null,
       "xColumns": null,
       "yColumns": null
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "name = \"ProductRevenueWorkflow\"\n",
    "\n",
    "workFlowRunner = WorkFlowRunner(name)\n",
    "workFlowRunner.runner()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c7366d3b-0d4b-4817-8120-373c3b97ca9e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "class TopSellingWorkflow:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def runner(self):\n",
    "        #Extraction\n",
    "        extractor = Order_items()\n",
    "        inputDf = extractor.extract()\n",
    "\n",
    "        #Tranformation: Preprocessing\n",
    "        preprocessed_order_items_df = get_preprocessed_order_items(inputDf)\n",
    "        \n",
    "        #Transformation: Aggregation\n",
    "        top_selling_transformer = TopSellingProduct()\n",
    "        top_selling_result = top_selling_transformer.transform(preprocessed_order_items_df)\n",
    "        display(top_selling_result)\n",
    "\n",
    "        top_selling_result.write.format(\"delta\").mode(\"overwrite\").save(\"abfss://gold@ecommerceproject.dfs.core.windows.net/Result/top_product/delta_table\")\n",
    "\n",
    "        spark.sql(\"create table if not exists eco.gold.top_product location 'abfss://gold@ecommerceproject.dfs.core.windows.net/Result/top_product/delta_table'\")\n",
    "        \n",
    "        gold_df = spark.table(\"eco.gold.top_product\")\n",
    "        display(gold_df)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "99175ccd-7c46-4c81-8334-b41f358638af",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "name = \"TopSellingWorkflow\"\n",
    "\n",
    "workFlowRunner = WorkFlowRunner(name)\n",
    "workFlowRunner.runner()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9d69fda1-7584-4df8-899d-cf2cc57d75df",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "source_path = \"abfss://stream-data@ecommerceproject.dfs.core.windows.net/\"\n",
    "bronze_table_path = \"abfss://bronze@ecommerceproject.dfs.core.windows.net/orders\"\n",
    "delta_table_path=\"abfss://bronze@ecommerceproject.dfs.core.windows.net/orders/delta_table/\"\n",
    "silver_table_path = \"abfss://silver@ecommerceproject.dfs.core.windows.net/orders/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "edb7a375-7b66-42c9-b0f9-da0b41512169",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "class TimelyRevenueWorkflow:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def runner(self):\n",
    "        #Extraction\n",
    "        extractor = Order_items()\n",
    "        orderitemDf = extractor.extract()\n",
    "\n",
    "        extractor = StreamingProcessor(source_path, bronze_table_path)\n",
    "        orderDf = extractor.start_streaming_job()\n",
    "        orderDf.awaitTermination(30)\n",
    "\n",
    "        #Tranformation: Preprocessing & Joins\n",
    "        preprocessed_order_items_df = get_preprocessed_order_items(orderitemDf)\n",
    "\n",
    "        preprocessed_order_df=IncrementalPreProcessor(delta_table_path, silver_table_path)\n",
    "        query=preprocessed_order_df.preprocess_stream()\n",
    "        query.awaitTermination(30)\n",
    "        preprocessed_orders_df=spark.readStream.format(\"delta\").load(silver_table_path)\n",
    "\n",
    "        #Transformation:Join\n",
    "        joined_df = order_items_join(preprocessed_orders_df,preprocessed_order_items_df)\n",
    "\n",
    "        #Transformation: Aggregation\n",
    "        revenue_by_time_transformer = RevenueTrendOverTimeTransformer()\n",
    "        revenue_result = revenue_by_time_transformer.transform(joined_df)\n",
    "        display(revenue_result)\n",
    "        # Start writing the transformation output to another table or sink\n",
    "        query = (revenue_result.writeStream\n",
    "                 .format(\"delta\")\n",
    "                 .outputMode(\"complete\")  # Or \"complete\" if doing aggregations\n",
    "                 .option(\"checkpointLocation\", \"abfss://gold@ecommerceproject.dfs.core.windows.net/Result/revenue_trend/checkpoint\")\n",
    "                 .start(\"abfss://gold@ecommerceproject.dfs.core.windows.net/Result/revenue_trend/delta_table\"))\n",
    "        query.awaitTermination(15)\n",
    "        spark.sql(\"create table if not exists eco.gold.revenue_trend location 'abfss://gold@ecommerceproject.dfs.core.windows.net/Result/revenue_trend/delta_table'\")\n",
    "        gold_stream_df = spark.readStream.format(\"delta\").load(\"abfss://gold@ecommerceproject.dfs.core.windows.net/Result/revenue_trend/delta_table\")\n",
    "        display(gold_stream_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2ef51cd6-0726-4894-a5cf-6bf765530c96",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "name = \"TimelyRevenueWorkflow\"\n",
    "\n",
    "workFlowRunner = WorkFlowRunner(name)\n",
    "workFlowRunner.runner()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5c7b28c3-4b7a-44be-a701-ac6b7ee16fc0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "class GeoRevenueWorkflow:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def runner(self):\n",
    "        #Extraction\n",
    "        orderi_extractor = Order_items()\n",
    "        orderitemDf = orderi_extractor.extract()\n",
    "        cust_extractor=Customers()\n",
    "        customerDf = cust_extractor.extract()\n",
    "        geo_extractor=Geolocation()\n",
    "        geoDf=geo_extractor.extract()\n",
    "        extractor = StreamingProcessor(source_path, bronze_table_path)\n",
    "        orderDf = extractor.start_streaming_job()\n",
    "        orderDf.awaitTermination(30)\n",
    "\n",
    "        #Tranformation: Preprocessing & Joins\n",
    "        preprocessed_order_items_df = get_preprocessed_order_items(orderitemDf)\n",
    "        preprocessed_customer_df = get_preprocessed_customers(customerDf)\n",
    "        preprocessed_geo_df=get_preprocessed_geolocation(geoDf)\n",
    "        preprocessed_order_df=IncrementalPreProcessor(delta_table_path, silver_table_path)\n",
    "        query=preprocessed_order_df.preprocess_stream()\n",
    "        query.awaitTermination(30)\n",
    "        preprocessed_order_df=spark.readStream.format(\"delta\").load(silver_table_path)\n",
    "\n",
    "        #Transformation:Join\n",
    "        joined_df = geographic_revenue_join(preprocessed_order_df,preprocessed_order_items_df,preprocessed_customer_df,preprocessed_geo_df)\n",
    "        # stream_joindf=spark.readStream.format(\"delta\").load(\"abfss://gold@ecomadls.dfs.core.windows.net/geographic_revenue/delta_table\")\n",
    "\n",
    "        #Transformation: Aggregation\n",
    "        revenue_by_state_transformer = GeographicRevenueTransformer()\n",
    "        revenue_result = revenue_by_state_transformer.transform(joined_df)\n",
    "        display(revenue_result)\n",
    "        query = (revenue_result.writeStream\n",
    "                 .format(\"delta\")\n",
    "                 .outputMode(\"complete\")  # Or \"complete\" if doing aggregations\n",
    "                 .option(\"checkpointLocation\", \"abfss://gold@ecommerceproject.dfs.core.windows.net/Result/geographic_revenue/checkpoint\")\n",
    "                 .start(\"abfss://gold@ecommerceproject.dfs.core.windows.net/Result/geographic_revenue/delta_table\"))\n",
    "        query.awaitTermination(15)\n",
    "        spark.sql(\"create table if not exists eco.gold.geographic_revenue location 'abfss://gold@ecommerceproject.dfs.core.windows.net/Result/geographic_revenue/delta_table'\")\n",
    "        gold_stream_df = spark.readStream.format(\"delta\").load(\"abfss://gold@ecommerceproject.dfs.core.windows.net/Result/geographic_revenue/delta_table\")\n",
    "        display(gold_stream_df)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "88d2039d-0821-4d76-9e79-60e73985f7ce",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "name = \"GeoRevenueWorkflow\"\n",
    "\n",
    "workFlowRunner = WorkFlowRunner(name)\n",
    "workFlowRunner.runner()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "35b39014-5f37-443b-b9ae-bf1b363428e5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "class CustomerValueWorkflow:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def runner(self):\n",
    "        #Extraction\n",
    "        orderi_extractor = Order_items()\n",
    "        orderitemDf = orderi_extractor.extract()\n",
    "\n",
    "        cust_extractor=Customers()\n",
    "        customerDf = cust_extractor.extract()\n",
    "\n",
    "        extractor = StreamingProcessor(source_path, bronze_table_path)\n",
    "        orderDf = extractor.start_streaming_job()\n",
    "        orderDf.awaitTermination(30)\n",
    "\n",
    "        #Tranformation: Preprocessing & Joins\n",
    "        preprocessed_order_items_df = get_preprocessed_order_items(orderitemDf)\n",
    "        preprocessed_customer_df = get_preprocessed_customers(customerDf)\n",
    "        preprocessed_order_df=IncrementalPreProcessor(delta_table_path, silver_table_path)\n",
    "        query=preprocessed_order_df.preprocess_stream()\n",
    "        query.awaitTermination(30)\n",
    "        preprocessed_order_df=spark.readStream.format(\"delta\").load(silver_table_path)\n",
    "\n",
    "        #Transformation:Join\n",
    "        joined_df = customer_spending_join(preprocessed_order_df,preprocessed_order_items_df,preprocessed_customer_df)\n",
    "        # stream_joindf=spark.readStream.format(\"delta\").load(\"abfss://gold@ecomadls.dfs.core.windows.net/customer_spending/delta_table\")\n",
    "\n",
    "        #Transformation: Aggregation\n",
    "        customer_value_transformer = CustomerValueTransformer()\n",
    "        revenue_result = customer_value_transformer.transform(joined_df)\n",
    "        display(revenue_result)\n",
    "        query = (revenue_result.writeStream\n",
    "                 .format(\"delta\")\n",
    "                 .outputMode(\"complete\")  \n",
    "                 .option(\"checkpointLocation\", \"abfss://gold@ecommerceproject.dfs.core.windows.net/Result/customer_value/checkpoint\")\n",
    "                 .start(\"abfss://gold@ecommerceproject.dfs.core.windows.net/Result/customer_value/delta_table\"))\n",
    "        query.awaitTermination(15)\n",
    "        spark.sql(\"create table eco.gold.customer_value location 'abfss://gold@ecommerceproject.dfs.core.windows.net/Result/customer_value/delta_table'\")\n",
    "        gold_stream_df = spark.readStream.format(\"delta\").load(\"abfss://gold@ecommerceproject.dfs.core.windows.net/Result/customer_value/delta_table\")\n",
    "        display(gold_stream_df)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "10c63b26-1666-4a70-a068-d14e5a9ec0ea",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "name = \"CustomerValueWorkflow\"\n",
    "\n",
    "workFlowRunner = WorkFlowRunner(name)\n",
    "workFlowRunner.runner()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [
    {
     "elements": [
      {
       "dashboardResultIndex": null,
       "elementNUID": "98e1e345-1982-4c9d-8164-2729e1789497",
       "elementType": "command",
       "guid": "4d16e1c0-09ff-4d93-9bf7-76fef429a7e1",
       "options": null,
       "position": {
        "height": 6,
        "width": 12,
        "x": 0,
        "y": 0,
        "z": null
       },
       "resultIndex": null
      },
      {
       "dashboardResultIndex": null,
       "elementNUID": "f85ad5b2-d6ed-493b-92a9-ebb5fcbdbc33",
       "elementType": "command",
       "guid": "bf8df00b-ca77-46bd-943e-ab5ddb33cc09",
       "options": null,
       "position": {
        "height": 8,
        "width": 15,
        "x": 0,
        "y": 6,
        "z": null
       },
       "resultIndex": null
      }
     ],
     "globalVars": {},
     "guid": "",
     "layoutOption": {
      "grid": true,
      "stack": true
     },
     "nuid": "3e9d56e5-2ecf-4c23-ba37-6d4dee3fa3de",
     "origId": 7017026954642397,
     "title": "Ecommerce",
     "version": "DashboardViewV1",
     "width": 1024
    }
   ],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 8992861733321346,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "Gold",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
